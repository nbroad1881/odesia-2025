{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exist 2022 - Task 1](#exist-2022---task-1)  \n",
    "[Exist 2022 - Task 2](#exist-2022---task-2)  \n",
    "[Exist 2023 - Task 1](#exist-2023---task-1)  \n",
    "[Exist 2023 - Task 2](#exist-2023---task-2)  \n",
    "[Exist 2023 - Task 3](#exist-2023---task-3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Loaded .env:\", load_dotenv(\"../../.env\", override=True))\n",
    "data_dir = Path(os.environ[\"PROJECT_DIR\"]) / \"data\" / \"host\"\n",
    "\n",
    "LANG = \"en\"\n",
    "SPLIT = \"train\"\n",
    "\n",
    "from prompts2 import (\n",
    "    prompt_t1_exist_2022,\n",
    "    prompt_t2_exist_2022,\n",
    "    prompt_t1_exist_2023,\n",
    "    prompt_t2_exist_2023,\n",
    "    prompt_t3_exist_2023,\n",
    "    numbered_t2_exist_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exist 2022 - Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an excellent assistant at identifying sexism in spanish tweets. You must decide whether or not a given tweet expresses ideas related to sexism in any of the three forms: it is sexist itself, it describes a sexist situation in which discrimination towards women occurs, or criticizes a sexist behaviour. The following statements show examples of sexist and not sexist messages, respectively.  Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\n",
      "\n",
      "\n",
      "Sexist tweet: Woman driving, be careful!\n",
      "Not sexist tweet: Just saw a woman wearing a mask outside spank her very tightly leashed dog and I gotta say I love learning absolutely everything about a stranger in a single instant.\n",
      "\n",
      "After thoroughly reading and analyzing the tweet, respond with either \"sexist\" or \"not sexist\".\n",
      "\n",
      "\n",
      "Tweet:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_t1_exist_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8961b6ff363b44d5a351e9bf57aee4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/513 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1_2022 = json.load(open(data_dir / \"exist_2022\" / f\"{SPLIT}_t1_{LANG}.json\"))\n",
    "\n",
    "print(len(t1_2022))\n",
    "\n",
    "label2str = {\"sexist\": \"sexist\", \"non-sexist\": \"not sexist\"}\n",
    "\n",
    "\n",
    "def format_t1_2022(x):\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        response = \"\"\n",
    "    else:\n",
    "        response = x[\"value\"]\n",
    "\n",
    "    return {\n",
    "        \"text\": prompt_t1_exist_2022 + x[\"text\"],\n",
    "        \"response\": response,\n",
    "    }\n",
    "\n",
    "\n",
    "ds_t1_2022 = Dataset.from_list(t1_2022)\n",
    "\n",
    "ds_t1_2022 = ds_t1_2022.map(format_t1_2022, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_case': 'EXIST2022',\n",
       " 'id': '159',\n",
       " 'text': 'You are an excellent assistant at identifying sexism in spanish tweets. You must decide whether or not a given tweet expresses ideas related to sexism in any of the three forms: it is sexist itself, it describes a sexist situation in which discrimination towards women occurs, or criticizes a sexist behaviour. The following statements show examples of sexist and not sexist messages, respectively.  Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\\n\\n\\nSexist tweet: Woman driving, be careful!\\nNot sexist tweet: Just saw a woman wearing a mask outside spank her very tightly leashed dog and I gotta say I love learning absolutely everything about a stranger in a single instant.\\n\\nAfter thoroughly reading and analyzing the tweet, respond with either \"sexist\" or \"not sexist\".\\n\\n\\nTweet:\\n\\n@spiderlily_x @marsfairyy he\\'s just ugly sorry',\n",
       " 'response': ''}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t1_2022.shuffle()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exist 2022 - Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an excellent assistant at categorizing sexism in spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\n",
      "\n",
      "Here are the category definitions:\n",
      "\n",
      "1. Ideological and inequality. This category includes all tweets that discredit the feminist movement in order to devalue, belittle and defame the struggle of women in any aspect\n",
      "of their lives. It also includes messages that reject inequality between men and women, or present men as victims of gender-based oppression. Some examples of this type of sexism discourse can be found in the following tweets:  \"#Feminism is a war on men, but it's also a war on women. It's a war on female nature, a war on femininity.\"\n",
      "2. Role stereotyping and dominance. This category includes messages that express false ideas about women that suggest they are more suitable or inappropriate for certain tasks. It also includes any claim that implies that men are somehow superior to women. \"Most women no longer have the desire or the knowledge to develop a high quality character, even if they wanted to.\"\n",
      "3. Objectification. Objectification and physical stereotyping includes messages where women are presented as objects apart from their dignity and personal aspects. We also include messages that assume or describe certain physical qualities that women must have in order to fulfill traditional gender roles, for example, ideas that suggest that women should maintain a standard and ideal of beauty or attacks on a woman's physique. \"No offense but I've never seen an attractive african american hooker. Not a single one\"\n",
      "4. Sexual violence. This category includes messages where sexual suggestions, requests or harassment of a sexual nature (rape or sexual assault) are made: \"I wanna touch your tits..you can't imagine what I can do on your body\"\n",
      "5. Misogyny and non sexual violence: this category includes expressions of hatred and violence towards women: \"Domestic abuse is never okay.... Unless your wife is a bitch.\"\n",
      "6. Not sexist. No sexism present in the text.\n",
      "\n",
      "For this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into ONLY ONE of the six categories by using the following labels:\n",
      "\n",
      "1. ideological inequality\n",
      "2. stereotyping dominance\n",
      "3. sexual violence\n",
      "4. misogyny and/or non-sexual violence\n",
      "5. objectification\n",
      "6. not sexist\n",
      "\n",
      "\n",
      "Tweet:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_t2_exist_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5571bcfb604d6dbd47c9855523633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/513 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t2_2022 = json.load(open(data_dir / \"exist_2022\" / f\"{SPLIT}_t2_{LANG}.json\"))\n",
    "\n",
    "print(len(t2_2022))\n",
    "\n",
    "label2str = {\n",
    "    \"non-sexist\": numbered_t2_exist_labels[5],\n",
    "    \"ideological-inequality\": numbered_t2_exist_labels[0],\n",
    "    \"stereotyping-dominance\": numbered_t2_exist_labels[1],\n",
    "    \"sexual-violence\": numbered_t2_exist_labels[2],\n",
    "    \"misogyny-non-sexual-violence\": numbered_t2_exist_labels[3],\n",
    "    \"objectification\": numbered_t2_exist_labels[4],\n",
    "}\n",
    "\n",
    "\n",
    "def format_t2_2022(x):\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        response = \"\"\n",
    "    else:\n",
    "        response = label2str[x[\"value\"]]\n",
    "\n",
    "    return {\n",
    "        \"text\": prompt_t2_exist_2022 + x[\"text\"],\n",
    "        \"response\": response,\n",
    "    }\n",
    "\n",
    "\n",
    "ds_t2_2022 = Dataset.from_list(t2_2022)\n",
    "ds_t2_2022 = ds_t2_2022.map(format_t2_2022, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_case': 'EXIST2022',\n",
       " 'id': '90',\n",
       " 'text': 'You are an excellent assistant at categorizing sexism in spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\\n\\nHere are the category definitions:\\n\\n1. Ideological and inequality. This category includes all tweets that discredit the feminist movement in order to devalue, belittle and defame the struggle of women in any aspect\\nof their lives. It also includes messages that reject inequality between men and women, or present men as victims of gender-based oppression. Some examples of this type of sexism discourse can be found in the following tweets:  \"#Feminism is a war on men, but it\\'s also a war on women. It\\'s a war on female nature, a war on femininity.\"\\n2. Role stereotyping and dominance. This category includes messages that express false ideas about women that suggest they are more suitable or inappropriate for certain tasks. It also includes any claim that implies that men are somehow superior to women. \"Most women no longer have the desire or the knowledge to develop a high quality character, even if they wanted to.\"\\n3. Objectification. Objectification and physical stereotyping includes messages where women are presented as objects apart from their dignity and personal aspects. We also include messages that assume or describe certain physical qualities that women must have in order to fulfill traditional gender roles, for example, ideas that suggest that women should maintain a standard and ideal of beauty or attacks on a woman\\'s physique. \"No offense but I\\'ve never seen an attractive african american hooker. Not a single one\"\\n4. Sexual violence. This category includes messages where sexual suggestions, requests or harassment of a sexual nature (rape or sexual assault) are made: \"I wanna touch your tits..you can\\'t imagine what I can do on your body\"\\n5. Misogyny and non sexual violence: this category includes expressions of hatred and violence towards women: \"Domestic abuse is never okay.... Unless your wife is a bitch.\"\\n6. Not sexist. No sexism present in the text.\\n\\nFor this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into ONLY ONE of the six categories by using the following labels:\\n\\n1. ideological inequality\\n2. stereotyping dominance\\n3. sexual violence\\n4. misogyny and/or non-sexual violence\\n5. objectification\\n6. not sexist\\n\\n\\nTweet:\\n\\n@ChristianWalk1r This post, designed for max outrage, proves how actually boring and repressed Little Walker is. The world he alludes to was pretty dark for \"men who just have sex with men,\" filled with lies, alcoholism, suicides, and sham marriages. He should be sexually boycotted, save for Milo',\n",
       " 'response': ''}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t2_2022.shuffle()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exist 2023 - Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an excellent assistant at identifying sexism in spanish tweets. You must decide whether or not a given tweet expresses ideas related to sexism in any of the three forms: it is sexist itself, it describes a sexist situation in which discrimination towards women occurs, or criticizes a sexist behaviour. The following statements show examples of sexist and not sexist messages, respectively.  Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\n",
      "\n",
      "\n",
      "Sexist tweet: Woman driving, be careful!\n",
      "Not sexist tweet: Just saw a woman wearing a mask outside spank her very tightly leashed dog and I gotta say I love learning absolutely everything about a stranger in a single instant.\n",
      "\n",
      "After thoroughly reading and analyzing the tweet, respond with either \"sexist\" or \"not sexist\".\n",
      "\n",
      "\n",
      "Tweet:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_t1_exist_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b8bcbdfb9a4c129e6d99be94213b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1_2023 = json.load(open(data_dir / \"exist_2023\" / f\"{SPLIT}_t1_{LANG}.json\"))\n",
    "\n",
    "print(len(t1_2023))\n",
    "\n",
    "def format_t1_2023(x):\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        response = \"\"\n",
    "    else:\n",
    "        yes_count = x[\"value\"].count(\"YES\")\n",
    "        response = f\"Sexist tweet score {yes_count}\"\n",
    "\n",
    "    if \"tweet\" not in x:\n",
    "        text_col = \"text\"\n",
    "    else:\n",
    "        text_col = \"tweet\"\n",
    "\n",
    "    return {\n",
    "        \"text\": prompt_t1_exist_2023 + x[text_col],\n",
    "        \"response\": response,\n",
    "    }\n",
    "\n",
    "def filter_t1_2023(x):\n",
    "    \"\"\"\n",
    "    Filter out samples that don't have agreement of at least 2/3 of the annotators.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        return True\n",
    "    \n",
    "    labels = list(chain(*x[\"value\"]))\n",
    "\n",
    "    counts = Counter(labels)\n",
    "\n",
    "    for k, v in counts.items():\n",
    "        if v >=4:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "ds_t1_2023 = Dataset.from_list(t1_2023)\n",
    "ds_t1_2023 = ds_t1_2023.map(format_t1_2023, remove_columns=ds_t1_2023.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'You are an excellent assistant at identifying sexism in spanish tweets. You must decide whether or not a given tweet expresses ideas related to sexism in any of the three forms: it is sexist itself, it describes a sexist situation in which discrimination towards women occurs, or criticizes a sexist behaviour. The following statements show examples of sexist and not sexist messages, respectively.  Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\\n\\n\\nSexist tweet: Woman driving, be careful!\\nNot sexist tweet: Just saw a woman wearing a mask outside spank her very tightly leashed dog and I gotta say I love learning absolutely everything about a stranger in a single instant.\\n\\nAfter thoroughly reading and analyzing the tweet, respond with either \"sexist\" or \"not sexist\".\\n\\n\\nTweet:\\n\\n@ArtsyAegis I read this and almost lost interest in the girl I like ðŸ˜³',\n",
       " 'response': 'Sexist tweet score 3'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t1_2023.shuffle()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exist 2023 - Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"You are an excellent assistant at identifying the source in sexist spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex. \n",
      "\n",
      "Category definitions:\n",
      "\n",
      "1. Direct sexist message. The intention was to write a message that is sexist by itself or incites to be sexist, as in: \"Women shouldn't code...perhaps be influencer/creator instead...it's their natural\n",
      "strength.\"\n",
      "2. Reported sexist message. The intention is to report and share a sexist situation suffered by a woman or women in first or third person, as in: \"Today, one of my year 1 class pupils could not believe he'd lost a race against a girl.\"\n",
      "3. Judgemental message. The intention was judgmental, since the tweet describes sexist situations or behaviours with the aim of condemning them. As in: \"21st century and we are still earning 25% less than men #Idonotrenounce.\"\n",
      "4. Not sexist message. No sexism present in the text.\n",
      "\n",
      "For this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into one of the above categories using the following labels:\n",
      "\n",
      "1. direct\n",
      "2. reported\n",
      "3. judgmental\n",
      "4. not sexist\n",
      "\n",
      "\n",
      "Tweet:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_t2_exist_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1259296ad2c5486c87d43ff05ded7d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t2_2023 = json.load(open(data_dir / \"exist_2023\" / f\"{SPLIT}_t2_{LANG}.json\"))\n",
    "\n",
    "print(len(t2_2023))\n",
    "\n",
    "label2str = {\n",
    "    \"-\": \"4. not sexist\",\n",
    "    \"DIRECT\": \"1. direct\",\n",
    "    \"REPORTED\": \"2. reported\",\n",
    "    \"JUDGEMENTAL\": \"3. judgmental\",\n",
    "}\n",
    "\n",
    "\n",
    "def format_t2_2023(x):\n",
    "    \n",
    "\n",
    "    if \"value\" not in x:\n",
    "        response = \"\"\n",
    "    else:\n",
    "        counts = Counter(x[\"value\"])\n",
    "        response = f\"Direct score {counts['DIRECT']}\"\n",
    "        response += f\"\\nReported score {counts['REPORTED']}\"\n",
    "        response += f\"\\nJudgmental score {counts['JUDGEMENTAL']}\"\n",
    "        response += f\"\\nNot sexist score {counts['-']}\"\n",
    "\n",
    "    text_col = \"tweet\"\n",
    "    if \"tweet\" not in x:\n",
    "        text_col = \"text\"\n",
    "\n",
    "    return {\"text\": prompt_t2_exist_2023 + x[text_col], \"response\": response}\n",
    "\n",
    "def filter_t2_2023(x):\n",
    "    \"\"\"\n",
    "    Filter out samples that don't have agreement of at least half of the annotators.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        return True\n",
    "\n",
    "    counts = Counter(x[\"value\"])\n",
    "\n",
    "    for k, v in counts.items():\n",
    "        if v >=4:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "ds_t2_2023 = Dataset.from_list(t2_2023)\n",
    "ds_t2_2023 = ds_t2_2023.map(format_t2_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '201594',\n",
       " 'lang': 'en',\n",
       " 'tweet': \"Rod Stewart apparently singing for a carol service for the first time since he was 7. My goodness he's still got it, that heart-breaking huskiness and the dishevelled laddish sexiness. Masses raised for @nordoffrobbins https://t.co/OZTplR0I21\",\n",
       " 'number_annotators': 6,\n",
       " 'annotators': ['Annotator_461',\n",
       "  'Annotator_462',\n",
       "  'Annotator_463',\n",
       "  'Annotator_464',\n",
       "  'Annotator_465',\n",
       "  'Annotator_466'],\n",
       " 'gender_annotators': ['F', 'F', 'M', 'M', 'M', 'F'],\n",
       " 'age_annotators': ['18-22', '23-45', '18-22', '23-45', '46+', '46+'],\n",
       " 'value': ['-', '-', '-', '-', '-', '-'],\n",
       " 'test_case': 'EXIST2023',\n",
       " 'text': '\"\"You are an excellent assistant at identifying the source in sexist spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex. \\n\\nCategory definitions:\\n\\n1. Direct sexist message. The intention was to write a message that is sexist by itself or incites to be sexist, as in: \"Women shouldn\\'t code...perhaps be influencer/creator instead...it\\'s their natural\\nstrength.\"\\n2. Reported sexist message. The intention is to report and share a sexist situation suffered by a woman or women in first or third person, as in: \"Today, one of my year 1 class pupils could not believe he\\'d lost a race against a girl.\"\\n3. Judgemental message. The intention was judgmental, since the tweet describes sexist situations or behaviours with the aim of condemning them. As in: \"21st century and we are still earning 25% less than men #Idonotrenounce.\"\\n4. Not sexist message. No sexism present in the text.\\n\\nFor this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into one of the above categories using the following labels:\\n\\n1. direct\\n2. reported\\n3. judgmental\\n4. not sexist\\n\\n\\nTweet:\\n\\nRod Stewart apparently singing for a carol service for the first time since he was 7. My goodness he\\'s still got it, that heart-breaking huskiness and the dishevelled laddish sexiness. Masses raised for @nordoffrobbins https://t.co/OZTplR0I21',\n",
       " 'response': 'Direct score 0\\nReported score 0\\nJudgmental score 0\\nNot sexist score 6'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t2_2023.shuffle()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exist 2023 - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an excellent assistant at categorizing sexism in spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\n",
      "\n",
      "Here are the category definitions:\n",
      "\n",
      "1. Ideological and inequality. This category includes all tweets that discredit the feminist movement in order to devalue, belittle and defame the struggle of women in any aspect\n",
      "of their lives. It also includes messages that reject inequality between men and women, or present men as victims of gender-based oppression. Some examples of this type of sexism discourse can be found in the following tweets:  \"#Feminism is a war on men, but it's also a war on women. It's a war on female nature, a war on femininity.\"\n",
      "2. Role stereotyping and dominance. This category includes messages that express false ideas about women that suggest they are more suitable or inappropriate for certain tasks. It also includes any claim that implies that men are somehow superior to women. \"Most women no longer have the desire or the knowledge to develop a high quality character, even if they wanted to.\"\n",
      "3. Objectification. Objectification and physical stereotyping includes messages where women are presented as objects apart from their dignity and personal aspects. We also include messages that assume or describe certain physical qualities that women must have in order to fulfill traditional gender roles, for example, ideas that suggest that women should maintain a standard and ideal of beauty or attacks on a woman's physique. \"No offense but I've never seen an attractive african american hooker. Not a single one\"\n",
      "4. Sexual violence. This category includes messages where sexual suggestions, requests or harassment of a sexual nature (rape or sexual assault) are made: \"I wanna touch your tits..you can't imagine what I can do on your body\"\n",
      "5. Misogyny and non sexual violence: this category includes expressions of hatred and violence towards women: \"Domestic abuse is never okay.... Unless your wife is a bitch.\"\n",
      "6. Not sexist. No sexism present in the text.\n",
      "\n",
      "For this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into ONE OR MORE of the above six categories using the following labels:\n",
      "\n",
      "1. ideological inequality\n",
      "2. stereotyping dominance\n",
      "3. sexual violence\n",
      "4. misogyny and/or non-sexual violence\n",
      "5. objectification\n",
      "6. not sexist\n",
      "\n",
      "\n",
      "Tweet:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_t3_exist_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2f24d149c7453b8c14ceaebfbce6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t3_2023 = json.load(open(data_dir / \"exist_2023\" / f\"{SPLIT}_t3_{LANG}.json\"))\n",
    "\n",
    "print(len(t3_2023))\n",
    "\n",
    "label2str = {'-': \"6. not sexist\", 'STEREOTYPING-DOMINANCE': \"2. stereotyping dominance\", 'OBJECTIFICATION': \"5. objectification\", 'IDEOLOGICAL-INEQUALITY': \"1. ideological inequality\", 'SEXUAL-VIOLENCE': \"3. sexual violence\", 'MISOGYNY-NON-SEXUAL-VIOLENCE': \"4. misogyny, non-sexual violence\"}\n",
    "\n",
    "def format_t3_2023(x):\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        response = \"\"\n",
    "    else:\n",
    "        labels = list(chain(*x[\"value\"]))\n",
    "\n",
    "        counts = Counter(labels)\n",
    "\n",
    "        response = f\"ideological inequality score {counts['IDEOLOGICAL-INEQUALITY']}\"\n",
    "        response += f\"\\nstereotyping dominance score {counts['STEREOTYPING-DOMINANCE']}\"\n",
    "        response += f\"\\nobjectification score {counts['OBJECTIFICATION']}\"\n",
    "        response += f\"\\nsexual violence score {counts['SEXUAL-VIOLENCE']}\"\n",
    "        response += f\"\\nmisogyny, non-sexual violence score {counts['MISOGYNY-NON-SEXUAL-VIOLENCE']}\"\n",
    "        response += f\"\\nNot sexist score {counts['-']}\"\n",
    "\n",
    "    if \"tweet\" not in x:\n",
    "        text_col = \"text\"\n",
    "    else:\n",
    "        text_col = \"tweet\"\n",
    "\n",
    "    return {\n",
    "        \"text\": prompt_t3_exist_2023 + x[text_col],\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "def filter_t3_2023(x):\n",
    "    \"\"\"\n",
    "    Filter out samples that don't have agreement between at least half of the annotators.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"value\" not in x:\n",
    "        return True\n",
    "\n",
    "    labels = list(chain(*x[\"value\"]))\n",
    "\n",
    "    counts = Counter(labels)\n",
    "\n",
    "    for k, v in counts.items():\n",
    "        if v >=3:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "ds_t3_2023 = Dataset.from_list(t3_2023)\n",
    "ds_t3_2023 = ds_t3_2023.map(format_t3_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '201532',\n",
       " 'lang': 'en',\n",
       " 'tweet': '@misskatie2021 I would like to fuck you ðŸ˜‚ðŸ˜‚ðŸ˜‚Ã€ french fan',\n",
       " 'number_annotators': 6,\n",
       " 'annotators': ['Annotator_455',\n",
       "  'Annotator_456',\n",
       "  'Annotator_457',\n",
       "  'Annotator_458',\n",
       "  'Annotator_459',\n",
       "  'Annotator_460'],\n",
       " 'gender_annotators': ['F', 'F', 'M', 'M', 'M', 'F'],\n",
       " 'age_annotators': ['18-22', '23-45', '18-22', '23-45', '46+', '46+'],\n",
       " 'value': [['-'],\n",
       "  ['SEXUAL-VIOLENCE'],\n",
       "  ['OBJECTIFICATION', 'SEXUAL-VIOLENCE'],\n",
       "  ['SEXUAL-VIOLENCE'],\n",
       "  ['SEXUAL-VIOLENCE'],\n",
       "  ['OBJECTIFICATION']],\n",
       " 'test_case': 'EXIST2023',\n",
       " 'text': 'You are an excellent assistant at categorizing sexism in spanish tweets. Sexism is defined as prejudice, stereotyping, or discrimination, typically against women, on the basis of sex.\\n\\nHere are the category definitions:\\n\\n1. Ideological and inequality. This category includes all tweets that discredit the feminist movement in order to devalue, belittle and defame the struggle of women in any aspect\\nof their lives. It also includes messages that reject inequality between men and women, or present men as victims of gender-based oppression. Some examples of this type of sexism discourse can be found in the following tweets:  \"#Feminism is a war on men, but it\\'s also a war on women. It\\'s a war on female nature, a war on femininity.\"\\n2. Role stereotyping and dominance. This category includes messages that express false ideas about women that suggest they are more suitable or inappropriate for certain tasks. It also includes any claim that implies that men are somehow superior to women. \"Most women no longer have the desire or the knowledge to develop a high quality character, even if they wanted to.\"\\n3. Objectification. Objectification and physical stereotyping includes messages where women are presented as objects apart from their dignity and personal aspects. We also include messages that assume or describe certain physical qualities that women must have in order to fulfill traditional gender roles, for example, ideas that suggest that women should maintain a standard and ideal of beauty or attacks on a woman\\'s physique. \"No offense but I\\'ve never seen an attractive african american hooker. Not a single one\"\\n4. Sexual violence. This category includes messages where sexual suggestions, requests or harassment of a sexual nature (rape or sexual assault) are made: \"I wanna touch your tits..you can\\'t imagine what I can do on your body\"\\n5. Misogyny and non sexual violence: this category includes expressions of hatred and violence towards women: \"Domestic abuse is never okay.... Unless your wife is a bitch.\"\\n6. Not sexist. No sexism present in the text.\\n\\nFor this task, you will be shown a tweet in Spanish. After thoroughly reading and analyzing the tweet, categorize the tweet into ONE OR MORE of the above six categories using the following labels:\\n\\n1. ideological inequality\\n2. stereotyping dominance\\n3. sexual violence\\n4. misogyny and/or non-sexual violence\\n5. objectification\\n6. not sexist\\n\\n\\nTweet:\\n\\n@misskatie2021 I would like to fuck you ðŸ˜‚ðŸ˜‚ðŸ˜‚Ã€ french fan',\n",
       " 'response': 'ideological inequality score 0\\nstereotyping dominance score 0\\nobjectification score 2\\nsexual violence score 4\\nmisogyny, non-sexual violence score 0\\nNot sexist score 1'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t3_2023.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ad115b6d7c47b88aeb58f7d97bfdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d466cb035047589870a2206d76298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39ee3994e9849c2b45e9e31c4d87c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeca5dba91941acadef28b4fae7b5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7102764b51844145800f951dfd2c48e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2559009"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cols = [\"text\", \"response\"]\n",
    "\n",
    "ds_t1_2022.remove_columns([x for x in ds_t1_2022.column_names if x not in final_cols]).to_parquet(data_dir / \"exist_2022\" / f\"{SPLIT}_t1_{LANG}_formatted.parquet\")\n",
    "ds_t2_2022.remove_columns([x for x in ds_t2_2022.column_names if x not in final_cols]).to_parquet(data_dir / \"exist_2022\" / f\"{SPLIT}_t2_{LANG}_formatted.parquet\")\n",
    "ds_t1_2023.remove_columns([x for x in ds_t1_2023.column_names if x not in final_cols]).to_parquet(data_dir / \"exist_2023\" / f\"{SPLIT}_t1_{LANG}_formatted.parquet\")\n",
    "ds_t2_2023.remove_columns([x for x in ds_t2_2023.column_names if x not in final_cols]).to_parquet(data_dir / \"exist_2023\" / f\"{SPLIT}_t2_{LANG}_formatted.parquet\")\n",
    "ds_t3_2023.remove_columns([x for x in ds_t3_2023.column_names if x not in final_cols]).to_parquet(data_dir / \"exist_2023\" / f\"{SPLIT}_t3_{LANG}_formatted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
